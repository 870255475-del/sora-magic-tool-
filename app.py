import streamlit as st
from PIL import Image, ImageDraw, ImageFont, ImageOps
import io
import os
import gc
import time
from openai import OpenAI

# ==========================================
# ğŸ‘‡ 0. æ ¸å¿ƒé…ç½® ğŸ‘‡
# ==========================================
st.set_page_config(
    page_title="Miss Pink Elf's Studio v27.0 (Ultimate)", 
    layout="wide", 
    page_icon="ğŸŒ¸",
    initial_sidebar_state="expanded"
)

# ==========================================
# ğŸ‘‡ 1. æ ¸å¿ƒæ ·å¼ä¸ç‰¹æ•ˆ ğŸ‘‡
# ==========================================
def load_elysia_style():
    # å®Œæ•´çš„ CSS æ ·å¼
    st.markdown("""
    <style>
    /* å…¨å±€ä¼˜åŒ– */
    .stApp {
        background: linear-gradient(135deg, #FFF0F5 0%, #E6E6FA 60%, #E0FFFF 100%);
        font-family: 'Comic Sans MS', 'Microsoft YaHei', sans-serif;
        color: #4A4A4A;
    }
    
    /* æ¨±èŠ±å®¹å™¨ */
    .sakura-container {
        position: fixed; top: 0; left: 0; width: 100%; height: 100%;
        pointer-events: none; z-index: 0; overflow: hidden;
    }
    .sakura {
        position: absolute; background-color: #FFB7C5; 
        border-radius: 100% 0 100% 0; opacity: 0.8;
        animation: fall linear infinite;
    }
    @keyframes fall {
        0% { opacity: 0; top: -10%; transform: translateX(0) rotate(0deg); }
        10% { opacity: 1; }
        100% { opacity: 0; top: 100%; transform: translateX(200px) rotate(720deg); }
    }

    /* ä¾§è¾¹æ  */
    section[data-testid="stSidebar"] {
        background-color: rgba(255, 255, 255, 0.75);
        backdrop-filter: blur(20px);
        border-right: 1px solid rgba(255, 255, 255, 0.8);
        z-index: 1;
    }

    /* æ ‡é¢˜ç‰¹æ•ˆ */
    h1, h2, h3, h4 {
        background: -webkit-linear-gradient(45deg, #FF69B4, #87CEFA);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 800 !important;
    }
    
    /* å¡ç‰‡æ‚¬æµ®ç‰¹æ•ˆ */
    .feature-card {
        background: rgba(255, 255, 255, 0.6);
        border-radius: 20px; padding: 25px;
        border: 2px solid #FFF;
        box-shadow: 0 8px 20px rgba(255, 182, 193, 0.15);
        transition: all 0.3s ease;
        text-align: center; height: 100%;
    }
    .feature-card:hover {
        transform: translateY(-8px) scale(1.02);
    }
    .emoji-icon { font-size: 3.5em; margin-bottom: 15px; display: block; animation: float 3s ease-in-out infinite; }
    @keyframes float { 0% {transform: translateY(0px);} 50% {transform: translateY(-10px);} 100% {transform: translateY(0px);} }

    /* è¾“å…¥æ¡† */
    .stTextInput input, .stNumberInput input, .stSelectbox div[data-baseweb="select"] {
        border-radius: 12px !important; border: 2px solid #FFE4E1 !important;
        background: rgba(255, 255, 255, 0.9) !important;
    }
    
    /* æŒ‰é’® */
    div.stButton > button {
        background: linear-gradient(90deg, #FF9A9E 0%, #FECFEF 100%);
        color: white !important;
        border-radius: 20px !important; border: none !important;
        box-shadow: 0 4px 12px rgba(255, 105, 180, 0.3) !important;
        transition: all 0.3s ease;
    }
    div.stButton > button:hover {
        transform: translateY(-2px);
    }
    </style>
    """, unsafe_allow_html=True)
    
    # å®Œæ•´çš„ JS è„šæœ¬
    st.markdown("""
    <script>
    function createSakura() {
        const container = document.createElement('div');
        container.className = 'sakura-container';
        document.body.appendChild(container);
        for (let i = 0; i < 40; i++) { 
            const petal = document.createElement('div');
            petal.className = 'sakura';
            const size = Math.random() * 12 + 6 + 'px';
            petal.style.width = size; petal.style.height = size;
            petal.style.left = Math.random() * 100 + 'vw';
            petal.style.animationDuration = Math.random() * 6 + 6 + 's';
            petal.style.animationDelay = Math.random() * 5 + 's';
            container.appendChild(petal);
        }
    }
    createSakura();
    </script>
    """, unsafe_allow_html=True)

load_elysia_style()

# ==========================================
# ğŸ‘‡ 2. å·¥å…·å‡½æ•°åº“ ğŸ‘‡
# ==========================================
@st.cache_resource
def get_font(size):
    possible_fonts = ["DejaVuSans-Bold.ttf", "arialbd.ttf", "Arial.ttf", "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf"]
    for font_name in possible_fonts:
        try:
            return ImageFont.truetype(font_name, size)
        except IOError:
            continue
    return ImageFont.load_default()

@st.cache_data(show_spinner=False)
def load_preview_image(file_name, _bytes):
    image = Image.open(io.BytesIO(_bytes))
    if image.mode in ('RGBA', 'P'): image = image.convert('RGB')
    image.thumbnail((400, 400))
    return image

def generate_sora_prompt_with_ai(api_key, base_url, model_name, global_style, cam, phys, ratio, motion, neg_prompt, shots_data):
    if not api_key: return "API Key not provided."
    if not base_url: base_url = "https://api.openai.com/v1"
    client = OpenAI(api_key=api_key, base_url=base_url)
    tech_specs = f"Specs: Ratio {ratio}, Motion {motion}/10, {cam}, {phys}"
    system_prompt = f"""You are an expert Sora 2 prompt engineer. Your task is to convert a storyboard into a narrative, physically-aware prompt.
    - Start with technical specs: "{tech_specs}"
    - Use timeline markers: [0s-2s].
    - Incorporate negative prompts: "Ensure high quality, avoid {neg_prompt}."
    - Output only the final prompt.
    """
    user_content = f"Global Style: {global_style}\nStoryboard:\n"
    current_time = 0.0
    for idx, item in enumerate(shots_data):
        end_time = current_time + item['dur']
        user_content += f"- Shot {idx+1} ({current_time}s-{end_time}s): View={item['shot_code']}, Action={item['desc']}\n"
        current_time = end_time
    try:
        response = client.chat.completions.create(model=model_name, messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}], temperature=0.7)
        return response.choices[0].message.content
    except Exception as e:
        return f"Error: {str(e)}"

# ==========================================
# ğŸ‘‡ 3. çŠ¶æ€ç®¡ç† & æ•°æ® ğŸ‘‡
# ==========================================
if "files" not in st.session_state: st.session_state.files = []
if 'last_result' not in st.session_state: st.session_state.last_result = None
if 'history' not in st.session_state: st.session_state.history = []

PRESETS_STYLE = {
    "ğŸŒ¸ çˆ±è‰å¸Œé›… (Anime)": "Dreamy Anime, Makoto Shinkai style, vibrant pastel colors, crystal clear lighting.",
    "ğŸ¥ è¯ºå…°ç”µå½±æ„Ÿ (IMAX)": "Shot on IMAX 70mm, Christopher Nolan style, realistic texture, muted tones.",
    "ğŸŒƒ èµ›åšæœ‹å…‹ (Cyberpunk)": "Neon-noir atmosphere, wet pavement reflections, volumetric fog, futuristic city.",
    "ğŸ“± æŠ–éŸ³çˆ†æ¬¾ (Viral)": "Trending on TikTok, high saturation, sharp focus, slow motion, 60fps.",
    "ğŸ§Š 3D æ¸²æŸ“ (C4D)": "Octane render, clay material, soft studio lighting, 3D character design."
}
PRESETS_CAMERA = {
    "Auto (è‡ªåŠ¨)": "Cinematic camera movement matching action", "Truck (æ¨ªç§»)": "Smooth trucking shot following subject",
    "Dolly In (æ¨é•œå¤´)": "Slow dolly in to emphasize emotion", "Rack Focus (å˜ç„¦)": "Rack focus from foreground to background",
    "FPV (ç©¿è¶Š)": "Fast FPV drone flight"
}
TAGS_PHYSICS = ["Volumetric Lighting", "Ray-traced Reflections", "Subsurface Scattering", "Fluid Simulation", "Motion Blur"]
RATIOS = {"16:9 (ç”µå½±)": (1920, 1080), "9:16 (æŠ–éŸ³)": (1080, 1920), "2.35:1 (å®½å±)": (1920, 816), "1:1 (æ–¹å›¾)": (1080, 1080)}
DEFAULT_NEG = "morphing, distortion, bad anatomy, blurry, watermark, text, low quality, glitch, extra limbs"
SHOT_OPTIONS = ["CU (ç‰¹å†™)", "MS (ä¸­æ™¯)", "LS (å…¨æ™¯)", "ECU (æç‰¹å†™)", "OTS (è¿‡è‚©é•œå¤´)", "FPV (ç¬¬ä¸€äººç§°)"]

# ==========================================
# ğŸ‘‡ 4. UI æ¸²æŸ“å‡½æ•° ğŸ‘‡
# ==========================================
def render_sidebar():
    with st.sidebar:
        if os.path.exists("elysia_cover.jpg"):
            st.image("elysia_cover.jpg", use_container_width=True)
        st.markdown("### ğŸ¹ é­”æ³•é…ç½®")
        with st.expander("ğŸ¤– è¿æ¥ AI å¤§è„‘", expanded=True):
            api_provider = st.selectbox("APIç±»å‹", ["è‡ªå®šä¹‰", "ç«å±±å¼•æ“ (è±†åŒ…)", "DeepSeek", "OpenAI"])
            base, model = "", ""
            if api_provider == "ç«å±±å¼•æ“ (è±†åŒ…)":
                st.markdown("ğŸ‘‰ [**ç‚¹æˆ‘æ³¨å†Œè±†åŒ…**](https://www.volcengine.com/product/doubao)")
                base = "https://ark.cn-beijing.volces.com/api/v3"
            elif api_provider == "DeepSeek":
                st.markdown("ğŸ‘‰ [**ç‚¹æˆ‘æ³¨å†Œ DeepSeek**](https://platform.deepseek.com/)")
                base = "https://api.deepseek.com"; model = "deepseek-chat"
            elif api_provider == "OpenAI":
                st.markdown("ğŸ‘‰ [**OpenAI å®˜ç½‘**](https://platform.openai.com/)")
                base = "https://api.openai.com/v1"; model = "gpt-4o"
            
            st.session_state.api_key = st.text_input("API Key", type="password")
            st.session_state.base_url = st.text_input("Base URL", value=base)
            st.session_state.model_name = st.text_input("Model", value=model, placeholder="è±†åŒ…è¯·å¡« Endpoint ID")

        st.markdown("---")
        st.markdown("#### ğŸ§ª Sora 2 ç‚¼é‡‘å°")
        st.session_state.selected_style = st.selectbox("ğŸ”® æ»¤é•œé£æ ¼", list(PRESETS_STYLE.keys()))
        st.session_state.cam_content = st.selectbox("ğŸ“· è¿é•œæ–¹å¼", list(PRESETS_CAMERA.keys()))
        st.session_state.phys_content = st.multiselect("ğŸŒŠ ç‰©ç†ä¸å…‰å½±", TAGS_PHYSICS, default=["Volumetric Lighting"])
        st.session_state.selected_ratio_name = st.selectbox("ç”»å¹…æ¯”ä¾‹", list(RATIOS.keys()))
        st.session_state.motion_strength = st.slider("âš¡ åŠ¨æ€å¹…åº¦", 1, 10, 5)
        st.session_state.neg_prompt = st.text_area("â›” è´Ÿé¢æç¤ºè¯", value=DEFAULT_NEG, height=70)
        st.markdown("---")
        c1, c2 = st.columns(2)
        with c1: st.session_state.border_width = st.slider("é—´è·", 0, 30, 15)
        with c2: st.session_state.output_quality = st.select_slider("ç”»è´¨", ["2K", "4K"], value="2K")
        st.session_state.scale_factor = 1.5 if st.session_state.output_quality == "4K" else 1.0
        st.markdown("---")
        with st.expander("â˜• æ‰“èµä½œè€…", expanded=False):
            if os.path.exists("pay.jpg"):
                st.image("pay.jpg")

def render_hero_section():
    st.info("ğŸ‘ˆ è¯·ä¸Šä¼ å›¾ç‰‡å¼€å§‹åˆ›ä½œ")
    st.markdown("<br>", unsafe_allow_html=True)
    col1, col2, col3 = st.columns(3)
    with col1: st.markdown("<div class='feature-card'><span class='emoji-icon'>ğŸ§ </span><h3>Sora 2 å†…æ ¸</h3><p>ä¼˜åŒ–çš„ç‰©ç†å¼•æ“æç¤ºè¯</p></div>", unsafe_allow_html=True)
    with col2: st.markdown("<div class='feature-card'><span class='emoji-icon'>ğŸ¬</span><h3>AI å¯¼æ¼”</h3><p>è‡ªåŠ¨ç¼–å†™æ—¶é—´è½´å‰§æœ¬</p></div>", unsafe_allow_html=True)
    with col3: st.markdown("<div class='feature-card'><span class='emoji-icon'>ğŸŒ¸</span><h3>å”¯ç¾ä½“éªŒ</h3><p>ä¸æ»‘é¢„è§ˆä¸ç¨³å®šäº¤äº’</p></div>", unsafe_allow_html=True)

def render_workspace():
    st.caption("ğŸ‘‡ ä½¿ç”¨å›¾ç‰‡ä¸‹æ–¹çš„ â¬†ï¸â¬‡ï¸ æŒ‰é’®è°ƒæ•´é¡ºåºï¼Œæˆ–åœ¨è¡¨å•ä¸­å‹¾é€‰åæ‰¹é‡åˆ é™¤")

    # æ’åºæŒ‰é’®
    cols_sort = st.columns(4)
    for i, file_data in enumerate(st.session_state.files):
        with cols_sort[i % 4]:
            with st.container():
                thumb = load_preview_image(file_data["name"], file_data["bytes"])
                st.image(thumb, use_container_width=True)
                def move_item(index, direction):
                    if direction == "up" and index > 0: st.session_state.files.insert(index - 1, st.session_state.files.pop(index))
                    elif direction == "down" and index < len(st.session_state.files) - 1: st.session_state.files.insert(index + 1, st.session_state.files.pop(index))
                c1, c2, _ = st.columns([1, 1, 4])
                with c1: st.button("â¬†ï¸", key=f"up_{i}", on_click=move_item, args=(i, "up"), use_container_width=True)
                with c2: st.button("â¬‡ï¸", key=f"down_{i}", on_click=move_item, args=(i, "down"), use_container_width=True)

    st.markdown("---")
    
    # è¡¨å•
    with st.form("storyboard_form"):
        st.write("#### ğŸ“ æ•…äº‹ç¼–ç»‡å°")
        shots_data = []
        form_cols = st.columns(4)
        delete_flags = {}
        for i, file_data in enumerate(st.session_state.files):
            with form_cols[i % 4]:
                st.caption(f"é•œå¤´ {i+1}")
                delete_flags[i] = st.checkbox("åˆ é™¤", key=f"del_{i}")
                
                s_type_full = st.selectbox("è§†è§’", SHOT_OPTIONS, key=f"s_{i}", label_visibility="collapsed")
                s_type_code = s_type_full.split(" ")[0]
                
                dur = st.number_input("ç§’", value=2.0, step=0.5, key=f"d_{i}", label_visibility="collapsed")
                desc = st.text_input("æè¿°", placeholder="åŠ¨ä½œ...", key=f"t_{i}", label_visibility="collapsed")
                shots_data.append({"bytes": file_data["bytes"], "shot_code": s_type_code, "dur": dur, "desc": desc})
        
        st.markdown("---")
        col_btn1, col_btn2 = st.columns([2, 1])
        with col_btn1: submit_btn = st.form_submit_button("âœ¨ æ–½å±•é­”æ³• âœ¨", type="primary", use_container_width=True)
        with col_btn2: delete_submit_btn = st.form_submit_button("ğŸ—‘ï¸ æ‰§è¡Œåˆ é™¤", use_container_width=True)

    # æŒ‰é’®é€»è¾‘
    if delete_submit_btn:
        indices_to_delete = sorted([i for i, checked in delete_flags.items() if checked], reverse=True)
        if indices_to_delete:
            for i in indices_to_delete: del st.session_state.files[i]
            st.success(f"å·²åˆ é™¤ {len(indices_to_delete)} å¼ å›¾ç‰‡ï¼")
            time.sleep(1); st.rerun()

    if submit_btn:
        with st.status("ğŸ’ é­”æ³•å’å”±ä¸­...", expanded=True) as status:
            st.write("ğŸ–¼ï¸ æ­£åœ¨æ„å»ºé»‘åº•ç™½å­—ä¸“ä¸šåˆ†é•œ...")
            target_size = RATIOS[st.session_state.selected_ratio_name]
            scale_factor = st.session_state.scale_factor
            border_width = st.session_state.border_width
            
            base_w, base_h = target_size
            final_w, final_h = int(base_w * scale_factor), int(base_h * scale_factor)
            count = len(shots_data)
            cols_count = 3
            rows_count = -(-count // cols_count)
            bar_height = int(final_h * 0.12)
            cell_h = final_h + bar_height
            total_w = (final_w * cols_count) + (border_width * (cols_count + 1))
            total_h = (cell_h * rows_count) + (border_width * (rows_count + 1))
            canvas = Image.new('RGB', (total_w, total_h), "#000000")
            font = get_font(int(bar_height * 0.5))
            
            for idx, item in enumerate(shots_data):
                src = Image.open(io.BytesIO(item["bytes"]))
                src = ImageOps.fit(src, (final_w, final_h), method=Image.Resampling.LANCZOS)
                cell = Image.new('RGB', (final_w, cell_h), "#000000")
                cell.paste(src, (0, bar_height))
                info_text = f"KF{idx+1} [{item['shot_code']} | {item['dur']}s]"
                cdraw = ImageDraw.Draw(cell)
                text_bbox = cdraw.textbbox((0, 0), info_text, font=font)
                text_h = text_bbox[3] - text_bbox[1]
                cdraw.text((int(20 * scale_factor), (bar_height - text_h) / 2), info_text, fill="#FFFFFF", font=font)
                r, c = idx // cols_count, idx % cols_count
                x = border_width + (c * (final_w + border_width))
                y = border_width + (r * (cell_h + border_width))
                canvas.paste(cell, (x, y))
            
            prompt_res = ""
            if 'api_key' in st.session_state and st.session_state.api_key:
                st.write("ğŸ§  AI æ­£åœ¨æ€è€ƒå…‰å½±ä¸è¿é•œ...")
                prompt_res = generate_sora_prompt_with_ai(
                    st.session_state.api_key, st.session_state.base_url, st.session_state.model_name,
                    PRESETS_STYLE[st.session_state.selected_style], PRESETS_CAMERA[st.session_state.cam_content], 
                    ", ".join(st.session_state.phys_content), st.session_state.selected_ratio_name,
                    st.session_state.motion_strength, st.session_state.neg_prompt, shots_data
                )
            
            status.update(label="âœ¨ é­”æ³•å®Œæˆï¼", state="complete")
            st.session_state.last_result = {"image": canvas, "prompt": prompt_res}
            st.session_state.history.append({"image": canvas, "prompt": prompt_res, "time": time.strftime("%H:%M")})
            gc.collect()

# ==========================================
# ğŸ‘‡ 5. ä¸»ç¨‹åºå…¥å£ ğŸ‘‡
# ==========================================
def main():
    render_sidebar()
    st.title("Miss Pink Elf's Studio v23.1")

    uploaded_files_now = st.file_uploader(
        "ğŸ“‚ **æ‹–å…¥å›¾ç‰‡**", type=['jpg', 'png', 'jpeg'], accept_multiple_files=True, key="uploader"
    )
    
    if uploaded_files_now:
        existing_names = {f['name'] for f in st.session_state.files}
        has_new_files = False
        for f in uploaded_files_now:
            if f.name not in existing_names:
                st.session_state.files.append({"name": f.name, "bytes": f.getvalue()})
                has_new_files = True
        if has_new_files:
            st.rerun()

    if not st.session_state.files:
        render_hero_section()
    else:
        render_workspace()
    
    if st.session_state.last_result:
        res = st.session_state.last_result
        st.balloons()
        tab1, tab2, tab3 = st.tabs(["ğŸ–¼ï¸ ä¸“ä¸šåˆ†é•œå›¾", "ğŸ“œ Sora 2 å’’è¯­", "ğŸ•°ï¸ å†å²è®°å½•"])
        with tab1:
            st.image(res["image"], use_container_width=True)
            buf = io.BytesIO()
            res["image"].save(buf, format="JPEG", quality=95)
            st.download_button("ğŸ“¥ ä¸‹è½½ä¸“ä¸šåˆ†é•œå›¾", buf.getvalue(), "sora_pro.jpg", "image/jpeg")
        with tab2:
            if res["prompt"]:
                st.code(res["prompt"], language="text")
                st.download_button("ğŸ“„ ä¸‹è½½æç¤ºè¯ (.txt)", res["prompt"], "prompt.txt", "text/plain")
        with tab3:
            st.caption("æœ¬æ¬¡ä¼šè¯çš„å†å²è®°å½•")
            for i, h in enumerate(reversed(st.session_state.history[:-1])):
                with st.expander(f"ğŸ•’ è®°å½• {h.get('time', 'N/A')}"):
                    st.image(h['image'], use_container_width=True)
                    if h['prompt']: st.code(h['prompt'])

if __name__ == "__main__":
    # This block is for local execution. It will be ignored by Streamlit Cloud.
    # We keep it here to allow "double-clicking" to run on a local windows machine.
    # It might cause issues on some cloud platforms if they don't handle it gracefully.
    # For maximum cloud compatibility, this block can be removed.
    import sys
    import subprocess
    if "STREAMLIT_subprocess_FLAG" not in os.environ:
        script_path = os.path.abspath(__file__)
        cmd = [sys.executable, "-m", "streamlit", "run", script_path]
        new_env = os.environ.copy()
        new_env["STREAMLIT_subprocess_FLAG"] = "true"
        try:
            subprocess.run(cmd, env=new_env)
        except KeyboardInterrupt:
            pass
        sys.exit(0)
    else:
        main()
