import streamlit as st
from PIL import Image, ImageDraw, ImageFont, ImageOps
import io
import os
import gc
import time
from openai import OpenAI
import math

# ==========================================
# ğŸ‘‡ 0. æ ¸å¿ƒé…ç½® ğŸ‘‡
# ==========================================
st.set_page_config(
    page_title="Miss Pink Elf's Studio v33.3 (Final)",
    layout="wide",
    page_icon="ğŸŒ¸",
    initial_sidebar_state="expanded"
)

# ==========================================
# ğŸ‘‡ 1. æ ¸å¿ƒæ ·å¼ä¸ç‰¹æ•ˆ ğŸ‘‡
# ==========================================
def load_elysia_style():
    # å®Œæ•´çš„ CSS æ ·å¼
    st.markdown("""
    <style>
    /* å…¨å±€ */
    .stApp { background: linear-gradient(135deg, #FFF0F5 0%, #E6E6FA 100%); font-family: 'Comic Sans MS', sans-serif; }
    h1, h2, h3, h4 { background: -webkit-linear-gradient(45deg, #FF6B6B, #FFA07A); -webkit-background-clip: text; -webkit-text-fill-color: transparent; font-weight: 800 !important; }

    /* ä¾§è¾¹æ  */
    section[data-testid="stSidebar"] { background-color: rgba(255, 255, 255, 0.75); backdrop-filter: blur(20px); }

    /* å¡ç‰‡ */
    .card {
        background: rgba(255,255,255,0.7);
        border-radius: 18px;
        padding: 15px;
        box-shadow: 0 6px 20px rgba(0,0,0,0.05);
        border: 2px solid transparent;
        transition: all 0.3s ease;
        margin-bottom: 20px; /* å¡ç‰‡é—´è· */
    }
    .card:hover { border-color: #FFB6C1; }

    /* è¾“å…¥æ§ä»¶ */
    .stTextInput input, .stNumberInput input, .stSelectbox div[data-baseweb="select"] {
        border-radius: 12px !important; border: 2px solid #FFE4E1 !important;
        background: rgba(255, 255, 255, 0.85) !important;
    }

    /* æäº¤æŒ‰é’® */
    div.stButton > button {
        background: linear-gradient(90deg, #FF6B6B 0%, #FFA07A 100%);
        color: white !important;
        border-radius: 20px !important; border: none !important;
        box-shadow: 0 4px 12px rgba(255, 107, 107, 0.4) !important;
    }
    .feature-card {
        background: rgba(255, 255, 255, 0.6);
        border-radius: 20px; padding: 25px;
        border: 2px solid #FFF;
        box-shadow: 0 8px 20px rgba(255, 182, 193, 0.15);
        text-align: center; height: 100%;
    }
    .emoji-icon { font-size: 3.5em; margin-bottom: 15px; display: block; }
    </style>
    """, unsafe_allow_html=True)

load_elysia_style()

# ==========================================
# ğŸ‘‡ 2. å·¥å…·å‡½æ•°åº“ ğŸ‘‡
# ==========================================
@st.cache_resource
def get_font(size):
    """å°è¯•åŠ è½½ç³»ç»Ÿä¸­å¯ç”¨çš„ç²—ä½“å­—ä½“ï¼Œå¤±è´¥åˆ™ä½¿ç”¨é»˜è®¤å­—ä½“"""
    possible_fonts = ["DejaVuSans-Bold.ttf", "arialbd.ttf", "Arial.ttf", "msyhbd.ttc"]
    for f in possible_fonts:
        try: return ImageFont.truetype(f, size)
        except IOError: continue
    return ImageFont.load_default()

@st.cache_data(show_spinner=False)
def load_preview_image(file_name, _bytes):
    """åŠ è½½å¹¶ç¼“å­˜ä¸Šä¼ å›¾ç‰‡çš„ç¼©ç•¥å›¾"""
    image = Image.open(io.BytesIO(_bytes))
    image.thumbnail((400, 400))
    return image

def generate_sora_prompt_with_ai(api_key, base_url, model_name, global_style, cam, phys, ratio, motion, neg_prompt, shots_data):
    """è°ƒç”¨AIæ¨¡å‹ç”ŸæˆSoraæç¤ºè¯"""
    if not api_key: return "é”™è¯¯: æœªæä¾› API Keyã€‚"
    if not base_url: base_url = "https://api.openai.com/v1"

    try:
        client = OpenAI(api_key=api_key, base_url=base_url)
    except Exception as e:
        return f"é”™è¯¯: åˆå§‹åŒ–OpenAIå®¢æˆ·ç«¯å¤±è´¥ - {str(e)}"

    tech_specs = f"Specs: Ratio {ratio}, Motion {motion}/10, {cam}, {', '.join(phys)}"
    system_prompt = (
        "You are an expert Sora 2 prompt engineer. Your task is to transform a simple storyboard into a rich, vivid, and coherent video prompt. "
        "Combine the global style, technical specifications, and shot-by-shot descriptions into a single, compelling paragraph. "
        "Describe the scene, characters, and actions in a continuous narrative, ensuring smooth transitions between shots. "
        "Focus on creating a cinematic and emotionally resonant experience. Don't mention the shot timings or shot numbers explicitly in the final prompt. "
        f"Finally, append the negative prompt: --neg {neg_prompt}"
    )

    user_content = f"Global Style: {global_style}\nTechnical Specs: {tech_specs}\nStoryboard:\n"
    current_time = 0.0
    for idx, item in enumerate(shots_data):
        end_time = current_time + item['dur']
        user_content += f"- Shot {idx+1} ({current_time:.1f}s-{end_time:.1f}s): View={item['shot_code']}, Action={item['desc']}\n"
        current_time = end_time

    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.75
        )
        return response.choices[0].message.content
    except Exception as e:
        st.error(f"è°ƒç”¨APIæ—¶å‡ºé”™: {str(e)}")
        return f"é”™è¯¯: è°ƒç”¨AIæ¨¡å‹å¤±è´¥ã€‚è¯·æ£€æŸ¥API Keyã€Base URLå’Œç½‘ç»œè¿æ¥ã€‚ {str(e)}"

# ==========================================
# ğŸ‘‡ 2.1. åˆ†é•œå›¾ç”Ÿæˆå‡½æ•° ğŸ‘‡
# ==========================================
def create_storyboard(files_data, shots_info, border, ratio_wh):
    """æ ¹æ®ä¸Šä¼ çš„å›¾ç‰‡å’Œä¿¡æ¯ï¼Œç”Ÿæˆä¸€å¼ å®Œæ•´çš„åˆ†é•œå›¾"""
    if not files_data:
        return None

    # è®¡ç®—å¸ƒå±€
    num_images = len(files_data)
    cols = 3
    rows = math.ceil(num_images / cols)

    # å®šä¹‰æ¯ä¸ªå•å…ƒæ ¼çš„å°ºå¯¸ (åŸºäº16:9)
    base_w, base_h = (480, 270)

    canvas_w = cols * base_w + (cols + 1) * border
    canvas_h = rows * base_h + (rows + 1) * border

    canvas = Image.new('RGB', (canvas_w, canvas_h), (255, 250, 250))
    draw = ImageDraw.Draw(canvas)

    title_font = get_font(24)
    text_font = get_font(16)

    for i, file_data in enumerate(files_data):
        row = i // cols
        col = i % cols

        # è®¡ç®—æ¯ä¸ªå•å…ƒæ ¼çš„èµ·å§‹åæ ‡
        x_start = col * base_w + (col + 1) * border
        y_start = row * base_h + (row + 1) * border

        # åŠ è½½å¹¶å¤„ç†å›¾ç‰‡
        img = Image.open(io.BytesIO(file_data['bytes']))
        # ä½¿ç”¨ ImageOps.fit æ¥è£å‰ªå’Œç¼©æ”¾å›¾ç‰‡ä»¥å¡«å……å•å…ƒæ ¼ï¼Œä¿æŒç”»é¢å†…å®¹
        img_thumb = ImageOps.fit(img, (base_w, base_h), Image.Resampling.LANCZOS)
        canvas.paste(img_thumb, (x_start, y_start))

        # æ·»åŠ åŠé€æ˜é»‘è‰²èƒŒæ™¯ä»¥å¢å¼ºæ–‡æœ¬å¯è¯»æ€§
        shot_data = shots_info[file_data['name']]
        info_text = f"é•œå¤´ {i+1} ({shot_data['duration']}s) - {shot_data['shot_type']}\n{shot_data['desc']}"

        # ç»˜åˆ¶æ–‡æœ¬
        text_pos_x = x_start + 10
        text_pos_y = y_start + 10
        draw.text((text_pos_x, text_pos_y), info_text, font=text_font, fill=(255,255,255), stroke_width=2, stroke_fill=(0,0,0))

    return canvas

# ==========================================
# ğŸ‘‡ 3. çŠ¶æ€ç®¡ç† & æ•°æ® ğŸ‘‡
# ==========================================
if "files" not in st.session_state: st.session_state.files = []
if "shots_data" not in st.session_state: st.session_state.shots_data = {}
if 'last_result' not in st.session_state: st.session_state.last_result = None

SHOT_OPTIONS = ["CU (ç‰¹å†™)", "MS (ä¸­æ™¯)", "LS (å…¨æ™¯)", "ECU (æç‰¹å†™)", "OTS (è¿‡è‚©)", "FPV (ç¬¬ä¸€äººç§°)"]
PRESETS_STYLE = {"ğŸŒ¸ çˆ±è‰å¸Œé›… (Anime)": "Dreamy Anime Style, pastel colors, sparkling effects, soft focus, beautiful and ethereal atmosphere, inspired by Makoto Shinkai.", "ğŸ¥ ç”µå½±è´¨æ„Ÿ (Cinematic)": "Shot on 35mm film, cinematic lighting, high contrast, anamorphic lens flare, professional color grading, realistic and immersive."}
PRESETS_CAMERA = {"Auto (è‡ªåŠ¨)": "Cinematic camera movement", "Truck (æ¨ªç§»)": "Smooth trucking shot", "Dolly (æ¨æ‹‰)": "Gentle dolly in/out shot", "Crane (æ‘‡è‡‚)": "Sweeping crane shot"}
TAGS_PHYSICS = ["Volumetric Lighting", "Ray-traced Reflections", "Fluid Simulation", "Depth of Field (DoF)", "Motion Blur"]
RATIOS = {"16:9 (ç”µå½±)": "16:9", "9:16 (æŠ–éŸ³)": "9:16"}
DEFAULT_NEG = "morphing, distortion, bad anatomy, blurry, watermark, text, low quality"
MAX_FILES = 6

# ==========================================
# ğŸ‘‡ 4. ä¾§è¾¹æ  UI ğŸ‘‡
# ==========================================
def render_sidebar():
    with st.sidebar:
        if os.path.exists("elysia_cover.jpg"):
            st.image("elysia_cover.jpg", use_container_width=True)
        st.markdown("### ğŸ¹ é­”æ³•é…ç½®")
        with st.expander("ğŸ¤– è¿æ¥ AI å¤§è„‘", expanded=True):
            api_provider = st.selectbox("APIç±»å‹", ["è‡ªå®šä¹‰", "ç«å±±å¼•æ“ (è±†åŒ…)", "DeepSeek", "OpenAI"])
            base, model = "", ""
            if api_provider == "ç«å±±å¼•æ“ (è±†åŒ…)":
                st.markdown("ğŸ‘‰ [**ç‚¹æˆ‘æ³¨å†Œè±†åŒ…**](https://www.volcengine.com/product/doubao)")
                base = "https://ark.cn-beijing.volces.com/api/v3"; model = "ep-20240722112448-l2a2o" # è¯·æ›¿æ¢ä¸ºä½ çš„æ¨¡å‹
            elif api_provider == "DeepSeek":
                st.markdown("ğŸ‘‰ [**ç‚¹æˆ‘æ³¨å†Œ DeepSeek**](https://platform.deepseek.com/)")
                base = "https://api.deepseek.com"; model = "deepseek-chat"
            st.session_state.api_key = st.text_input("API Key", type="password", placeholder="è¯·è¾“å…¥ä½ çš„ API Key")
            st.session_state.base_url = st.text_input("Base URL", value=base)
            st.session_state.model_name = st.text_input("Model", value=model)

        st.markdown("---")
        st.markdown("#### ğŸ§ª Sora 2 ç‚¼é‡‘å°")
        st.session_state.selected_style_key = st.selectbox("ğŸ”® æ»¤é•œé£æ ¼", list(PRESETS_STYLE.keys()))
        st.session_state.cam_content_key = st.selectbox("ğŸ“· è¿é•œæ–¹å¼", list(PRESETS_CAMERA.keys()))
        st.session_state.phys_content = st.multiselect("ğŸŒŠ ç‰©ç†ä¸å…‰å½±", TAGS_PHYSICS, default=["Volumetric Lighting"])
        st.session_state.selected_ratio_name = st.selectbox("ç”»å¹…æ¯”ä¾‹", list(RATIOS.keys()))
        st.session_state.motion_strength = st.slider("âš¡ åŠ¨æ€å¹…åº¦", 1, 10, 5)
        st.session_state.neg_prompt = st.text_area("â›” è´Ÿé¢æç¤ºè¯", value=DEFAULT_NEG, height=70)
        st.markdown("---")
        st.session_state.border_width = st.slider("ğŸ–¼ï¸ é—´è·", 0, 50, 20)
        st.markdown("---")
        with st.expander("â˜• æ‰“èµä½œè€…", expanded=False):
            if os.path.exists("pay.jpg"):
                st.image("pay.jpg")

# ==========================================
# ğŸ‘‡ 5. ä¸»å·¥ä½œå° ğŸ‘‡
# ==========================================
def render_hero_section():
    st.info(f"ğŸ‘ˆ è¯·åœ¨å·¦ä¾§ä¸Šä¼ å›¾ç‰‡å¼€å§‹åˆ›ä½œ (æœ€å¤š {MAX_FILES} å¼ )")

def main():
    render_sidebar()
    st.title("Miss Pink Elf's Studio v33.3")

    newly_uploaded_files = st.file_uploader(f"ğŸ“‚ **æ‹–å…¥å›¾ç‰‡ (æœ€å¤š {MAX_FILES} å¼ )**", type=['jpg', 'png', 'jpeg'], accept_multiple_files=True, key="uploader")
    if newly_uploaded_files:
        if len(st.session_state.files) + len(newly_uploaded_files) > MAX_FILES:
            st.warning(f"æ€»æ•°è¶…å‡ºé™åˆ¶ï¼æœ€å¤šåªèƒ½ä¸Šä¼  {MAX_FILES} å¼ å›¾ç‰‡ã€‚")
        else:
            existing_names = {f['name'] for f in st.session_state.files}
            files_to_add = [f for f in newly_uploaded_files if f.name not in existing_names]
            for file in files_to_add:
                st.session_state.files.append({"name": file.name, "bytes": file.getvalue()})
                st.session_state.shots_data[file.name] = {"shot_type": "MS (ä¸­æ™¯)", "duration": 2.0, "desc": ""}
            if files_to_add:
                st.rerun()

    if not st.session_state.files:
        render_hero_section()
    else:
        st.caption("ğŸ‘‡ åœ¨æ¯ä¸ªå¡ç‰‡ä¸­ç¼–è¾‘ä¿¡æ¯ï¼Œä½¿ç”¨ â¬†ï¸â¬‡ï¸ è°ƒæ•´é¡ºåºï¼Œæˆ–ç‚¹å‡» âŒ åˆ é™¤")
        st.write("---")

        cols = st.columns(3)

        def move_item(index, direction):
            if direction == "up" and index > 0: st.session_state.files.insert(index - 1, st.session_state.files.pop(index))
            elif direction == "down" and index < len(st.session_state.files) - 1: st.session_state.files.insert(index + 1, st.session_state.files.pop(index))
            st.rerun()

        def delete_item(index):
            file_name = st.session_state.files[index]['name']
            del st.session_state.shots_data[file_name]
            st.session_state.files.pop(index)
            st.rerun()

        for i, file_data in enumerate(st.session_state.files):
            with cols[i % 3]:
                with st.container():
                    st.markdown('<div class="card">', unsafe_allow_html=True)
                    st.image(load_preview_image(file_data["name"], file_data["bytes"]), use_container_width=True)

                    file_name = file_data['name']
                    shot_info = st.session_state.shots_data.get(file_name, {})

                    st.caption(f"é•œå¤´ {i+1}: {file_name[:20]}")

                    s_type = st.selectbox("è§†è§’", SHOT_OPTIONS, index=SHOT_OPTIONS.index(shot_info.get('shot_type', "MS (ä¸­æ™¯)")), key=f"s_{i}")
                    dur = st.number_input("ç§’", value=shot_info.get('duration', 2.0), min_value=0.5, step=0.5, key=f"d_{i}")
                    desc = st.text_input("æè¿°", value=shot_info.get('desc', ''), placeholder="è¿™ä¸ªé•œå¤´é‡Œå‘ç”Ÿäº†ä»€ä¹ˆ...", key=f"t_{i}")

                    st.session_state.shots_data[file_name] = {"shot_type": s_type, "duration": dur, "desc": desc}

                    c1, c2, c3 = st.columns([1,1,1])
                    with c1: st.button("â¬†ï¸", key=f"up_{i}", on_click=move_item, args=(i, "up"), use_container_width=True, disabled=(i==0))
                    with c2: st.button("â¬‡ï¸", key=f"down_{i}", on_click=move_item, args=(i, "down"), use_container_width=True, disabled=(i==len(st.session_state.files)-1))
                    with c3: st.button("âŒ", key=f"del_{i}", on_click=delete_item, args=(i,), use_container_width=True, type="primary")

                    st.markdown('</div>', unsafe_allow_html=True)

        st.write("---")
        if st.button("âœ¨ æ–½å±•é­”æ³• (ç”Ÿæˆåˆ†é•œ + å’’è¯­) âœ¨", type="primary", use_container_width=True):
            final_shots_data = []
            for file_data in st.session_state.files:
                shot_info = st.session_state.shots_data[file_data['name']]
                # ã€ä¿®æ”¹ã€‘æ³¨é‡Šæ‰æè¿°æ£€æŸ¥ï¼Œå…è®¸ä¸ºç©º
                # if not shot_info['desc'].strip():
                #     st.error(f"é”™è¯¯ï¼šé•œå¤´ {file_data['name']} çš„æè¿°ä¸èƒ½ä¸ºç©ºï¼")
                #     return # ç»ˆæ­¢æ‰§è¡Œ

                final_shots_data.append({
                    "bytes": file_data["bytes"],
                    "shot_code": shot_info['shot_type'].split(" ")[0],
                    "dur": shot_info['duration'],
                    "desc": shot_info['desc']
                })

            with st.status("ğŸ’ é­”æ³•å’å”±ä¸­...", expanded=True) as status:
                status.write("ğŸ–¼ï¸ æ­£åœ¨æ„å»ºä¸“ä¸šåˆ†é•œ...")

                canvas = create_storyboard(st.session_state.files, st.session_state.shots_data, st.session_state.border_width, RATIOS[st.session_state.selected_ratio_name])

                prompt_res = ""
                if 'api_key' in st.session_state and st.session_state.api_key:
                    status.write("ğŸ§  AI æ­£åœ¨æ’°å†™å‰§æœ¬...")
                    prompt_res = generate_sora_prompt_with_ai(
                        api_key=st.session_state.api_key,
                        base_url=st.session_state.base_url,
                        model_name=st.session_state.model_name,
                        global_style=PRESETS_STYLE[st.session_state.selected_style_key],
                        cam=PRESETS_CAMERA[st.session_state.cam_content_key],
                        phys=st.session_state.phys_content,
                        ratio=RATIOS[st.session_state.selected_ratio_name],
                        motion=st.session_state.motion_strength,
                        neg_prompt=st.session_state.neg_prompt,
                        shots_data=final_shots_data
                    )
                else:
                    prompt_res = "æç¤º: æœªé…ç½® API Keyï¼Œè·³è¿‡AIç”Ÿæˆã€‚è¯·åœ¨å·¦ä¾§é…ç½®åé‡è¯•ã€‚"

                status.update(label="âœ¨ é­”æ³•å®Œæˆï¼", state="complete")

                buf = io.BytesIO()
                if canvas:
                    canvas.save(buf, format="JPEG")
                    image_bytes = buf.getvalue()
                else:
                    image_bytes = None

                st.session_state.last_result = {"image_bytes": image_bytes, "prompt": prompt_res}
                st.rerun()

        if st.session_state.last_result:
            # ã€ä¿®æ”¹ã€‘æ³¨é‡Šæ‰æ°”çƒåŠ¨ç”»
            # st.balloons()
            st.markdown("---")
            st.markdown("### ğŸ“œ é­”æ³•å·è½´å·²å±•å¼€")

            prompt_result = st.session_state.last_result["prompt"]
            if prompt_result.startswith("é”™è¯¯:"):
                st.error(prompt_result)
            else:
                st.text_area("âœ¨ AI ç”Ÿæˆçš„Soraæç¤ºè¯", value=prompt_result, height=250)

            if st.session_state.last_result["image_bytes"]:
                st.markdown("---")
                st.markdown("### ğŸ–¼ï¸ ç”Ÿæˆçš„åˆ†é•œæ€»è§ˆ")
                st.image(st.session_state.last_result["image_bytes"], use_container_width=True)

if __name__ == "__main__":
    main()
