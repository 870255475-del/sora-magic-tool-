import streamlit as st
from PIL import Image, ImageDraw, ImageFont, ImageOps
import io
import os
import gc
import time
import random
from openai import OpenAI

# ==========================================
# ğŸ‘‡ 0. æ ¸å¿ƒé…ç½® (å·²ç§»é™¤æœ¬åœ°å¯åŠ¨ä»£ç ï¼Œäº‘ç«¯ä¸“ç”¨) ğŸ‘‡
# ==========================================
st.set_page_config(
    page_title="Miss Pink Elf's Studio v10.0", 
    layout="wide", 
    page_icon="ğŸŒ¸",
    initial_sidebar_state="expanded"
)

# ==========================================
# ğŸ‘‡ 1. æ ¸å¿ƒæ ·å¼ä¸ç‰¹æ•ˆ (CSS/JS) ğŸ‘‡
# ==========================================
def load_elysia_style():
    sakura_css = """
    <style>
    /* å…¨å±€ä¼˜åŒ– */
    .stApp {
        background: linear-gradient(135deg, #FFF0F5 0%, #E6E6FA 60%, #E0FFFF 100%);
        font-family: 'Comic Sans MS', 'Microsoft YaHei', sans-serif;
        color: #4A4A4A;
    }
    
    /* æ¨±èŠ±å®¹å™¨ (é˜²é®æŒ¡ä¼˜åŒ–) */
    .sakura-container {
        position: fixed; top: 0; left: 0; width: 100%; height: 100%;
        pointer-events: none; z-index: 0; overflow: hidden;
    }
    .sakura {
        position: absolute; background-color: #FFB7C5; 
        border-radius: 100% 0 100% 0; opacity: 0.8;
        animation: fall linear infinite;
    }
    @keyframes fall {
        0% { opacity: 0; top: -10%; transform: translateX(0) rotate(0deg); }
        10% { opacity: 1; }
        100% { opacity: 0; top: 100%; transform: translateX(200px) rotate(720deg); }
    }

    /* ä¾§è¾¹æ è¿›åŒ–ï¼šç»ç’ƒæ‹Ÿæ€ v2.0 */
    section[data-testid="stSidebar"] {
        background-color: rgba(255, 255, 255, 0.75);
        backdrop-filter: blur(20px);
        border-right: 1px solid rgba(255, 255, 255, 0.8);
        box-shadow: 2px 0 15px rgba(255, 192, 203, 0.15);
        z-index: 1;
    }

    /* æ ‡é¢˜ç‰¹æ•ˆ */
    h1, h2, h3 {
        background: linear-gradient(45deg, #FF69B4, #87CEFA);
        -webkit-background-clip: text;
        -webkit-text-fill-color: transparent;
        font-weight: 900 !important;
        letter-spacing: 1px;
    }
    
    /* å¡ç‰‡æ‚¬æµ®ç‰¹æ•ˆ */
    .feature-card {
        background: rgba(255, 255, 255, 0.6);
        border-radius: 20px; padding: 25px;
        border: 2px solid #FFF;
        box-shadow: 0 8px 20px rgba(255, 182, 193, 0.15);
        transition: all 0.3s ease;
        text-align: center; height: 100%;
    }
    .feature-card:hover {
        transform: translateY(-8px) scale(1.02);
        background: rgba(255, 255, 255, 0.95);
        border-color: #FF69B4;
        box-shadow: 0 15px 30px rgba(255, 105, 180, 0.3);
    }
    .emoji-icon { font-size: 3.5em; margin-bottom: 15px; display: block; animation: float 3s ease-in-out infinite; }
    @keyframes float { 0% {transform: translateY(0px);} 50% {transform: translateY(-10px);} 100% {transform: translateY(0px);} }

    /* æ§ä»¶æè‡´ç¾åŒ– */
    .stTextInput input, .stNumberInput input, .stSelectbox div[data-baseweb="select"] {
        border-radius: 12px !important; border: 2px solid #FFE4E1 !important;
        background: rgba(255, 255, 255, 0.85) !important;
        transition: border-color 0.3s;
    }
    .stTextInput input:focus, .stNumberInput input:focus {
        border-color: #FF69B4 !important;
        box-shadow: 0 0 10px rgba(255, 105, 180, 0.2);
    }

    /* æŒ‰é’®ï¼šæµå…‰æº¢å½© */
    div.stButton > button {
        background: linear-gradient(90deg, #FF9A9E 0%, #FECFEF 50%, #FF9A9E 100%);
        background-size: 200% auto;
        color: white !important;
        border-radius: 25px !important; border: none !important;
        box-shadow: 0 4px 15px rgba(255, 105, 180, 0.4) !important;
        transition: all 0.4s ease;
    }
    div.stButton > button:hover {
        background-position: right center;
        transform: scale(1.03);
    }
    </style>
    """
    
    sakura_js = """
    <script>
    function createSakura() {
        const container = document.createElement('div');
        container.className = 'sakura-container';
        document.body.appendChild(container);
        for (let i = 0; i < 40; i++) { 
            const petal = document.createElement('div');
            petal.className = 'sakura';
            const size = Math.random() * 12 + 6 + 'px';
            petal.style.width = size; petal.style.height = size;
            petal.style.left = Math.random() * 100 + 'vw';
            petal.style.animationDuration = Math.random() * 6 + 6 + 's';
            petal.style.animationDelay = Math.random() * 5 + 's';
            container.appendChild(petal);
        }
    }
    createSakura();
    </script>
    """
    st.markdown(sakura_css + sakura_js, unsafe_allow_html=True)

load_elysia_style()

# ==========================================
# ğŸ‘‡ 2. å·¥å…·å‡½æ•°åº“ (Utils) ğŸ‘‡
# ==========================================
@st.cache_resource
def get_font(size):
    # åˆ›å»ºä¸€ä¸ªå­—ä½“å¤‡é€‰åˆ—è¡¨ï¼ŒæŒ‰æ¨èé¡ºåºæ’åˆ—
    # DejaVuSans-Bold åœ¨ Linux æœåŠ¡å™¨ä¸Šéå¸¸å¸¸è§ï¼Œä¸”æ•ˆæœå¾ˆå¥½
    possible_fonts = [
        "DejaVuSans-Bold.ttf",  # Linux æœåŠ¡å™¨é¦–é€‰
        "arialbd.ttf",          # Windows ä¸Šçš„å¤‡é€‰
        "Arial Bold.ttf",       # å¦ä¸€ç§ Windows å‘½å
        "Arial.ttf",            # å¦‚æœç²—ä½“æ²¡æœ‰ï¼Œç”¨å¸¸è§„ä½“ä¹Ÿè¡Œ
        "/usr/share/fonts/truetype/dejavu/DejaVuSans-Bold.ttf" # åœ¨æŸäº› Linux ä¸Šçš„ç»å¯¹è·¯å¾„
    ]
    
    # æŒ¨ä¸ªå°è¯•åˆ—è¡¨é‡Œçš„å­—ä½“
    for font_name in possible_fonts:
        try:
            # åªè¦æ‰¾åˆ°ä¸€ä¸ªèƒ½ç”¨çš„ï¼Œå°±ç«‹åˆ»è¿”å›
            return ImageFont.truetype(font_name, size)
        except IOError:
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°±é»˜é»˜åœ°ç»§ç»­å°è¯•ä¸‹ä¸€ä¸ª
            continue
            
    # å¦‚æœåˆ—è¡¨é‡Œæ‰€æœ‰å­—ä½“éƒ½å¤±è´¥äº†ï¼Œæ‰ä½¿ç”¨æœ€åçš„å¤‡ç”¨æ–¹æ¡ˆ
    return ImageFont.load_default()

@st.cache_data(show_spinner=False)
def load_preview_image(uploaded_file):
    image = Image.open(uploaded_file)
    if image.mode in ('RGBA', 'P'): image = image.convert('RGB')
    image.thumbnail((400, 400)) 
    return image

# æ ¸å¿ƒ AI é€»è¾‘
def generate_sora_prompt_with_ai(api_key, base_url, model_name, global_style, cam, phys, ratio, motion, neg_prompt, shots_data):
    if not base_url: base_url = "https://api.openai.com/v1"
    client = OpenAI(api_key=api_key, base_url=base_url)
    
    tech_specs = f"Specs: Ratio {ratio}, Motion {motion}/10, {cam}, {phys}"
    
    system_prompt = f"""
    ä½ æ˜¯ç”±çˆ±è‰å¸Œé›…å¼ºåŒ–çš„ Sora 2 æç¤ºè¯æ¶æ„å¸ˆã€‚
    ã€ä»»åŠ¡ç›®æ ‡ã€‘
    å°†ç”¨æˆ·çš„é™æ€åˆ†é•œè¡¨ï¼Œè½¬åŒ–ä¸ºä¸€æ®µåŒ…å« "ç‰©ç†é€»è¾‘" å’Œ "å™äº‹æµåŠ¨" çš„ Sora 2 (Turbo) è§†é¢‘æç¤ºè¯ã€‚
    ã€è¾“å‡ºè¦æ±‚ã€‘
    1. å¿…é¡»ä»¥æŠ€æœ¯å‚æ•°å¼€å¤´: "{tech_specs}"
    2. å¿…é¡»ä½¿ç”¨æ—¶é—´è½´æ ‡è®°: [0s-2s], [2s-4s]...
    3. å¿…é¡»èå…¥è´Ÿé¢æç¤ºè¯é€»è¾‘: "Ensure high quality, avoid {neg_prompt}."
    4. ä¸è¦è¾“å‡ºä½ çš„æ€è€ƒè¿‡ç¨‹ï¼Œåªè¾“å‡ºæœ€ç»ˆçš„ Promptã€‚
    """
    
    user_content = f"Global Style: {global_style}\nStoryboard Sequences:\n"
    current_time = 0.0
    for idx, item in enumerate(shots_data):
        end_time = current_time + item['dur']
        user_content += f"- Sequence {idx+1} ({current_time}s-{end_time}s): Camera View={item['shot_code']}, Subject Action={item['desc']}\n"
        current_time = end_time
        
    try:
        response = client.chat.completions.create(
            model=model_name,
            messages=[{"role": "system", "content": system_prompt}, {"role": "user", "content": user_content}],
            temperature=0.7
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"âŒ é­”æ³•ä¸­æ–­: {str(e)}"

# ==========================================
# ğŸ‘‡ 3. é…ç½®æ•°æ®ä¸çŠ¶æ€ç®¡ç† ğŸ‘‡
# ==========================================
PRESETS_STYLE = {
    "ğŸŒ¸ çˆ±è‰å¸Œé›… (Anime)": "Dreamy Anime, Makoto Shinkai style, vibrant pastel colors, crystal clear lighting.",
    "ğŸ¥ è¯ºå…°ç”µå½±æ„Ÿ (IMAX)": "Shot on IMAX 70mm, Christopher Nolan style, realistic texture, muted tones.",
    "ğŸŒƒ èµ›åšæœ‹å…‹ (Cyberpunk)": "Neon-noir atmosphere, wet pavement reflections, volumetric fog, futuristic city.",
    "ğŸ“± æŠ–éŸ³çˆ†æ¬¾ (Viral)": "Trending on TikTok, high saturation, sharp focus, slow motion, 60fps.",
    "ğŸ§Š 3D æ¸²æŸ“ (C4D)": "Octane render, clay material, soft studio lighting, 3D character design."
}
PRESETS_CAMERA = {
    "Auto (è‡ªåŠ¨)": "Cinematic camera movement matching action",
    "Truck (æ¨ªç§»)": "Smooth trucking shot following subject",
    "Dolly In (æ¨é•œå¤´)": "Slow dolly in to emphasize emotion",
    "Rack Focus (å˜ç„¦)": "Rack focus from foreground to background",
    "FPV (ç©¿è¶Š)": "Fast FPV drone flight"
}
TAGS_PHYSICS = ["Volumetric Lighting", "Ray-traced Reflections", "Subsurface Scattering", "Fluid Simulation", "Motion Blur"]
RATIOS = {"16:9 (ç”µå½±)": (1920, 1080), "9:16 (æŠ–éŸ³)": (1080, 1920), "2.35:1 (å®½å±)": (1920, 816), "1:1 (æ–¹å›¾)": (1080, 1080)}
DEFAULT_NEG = "morphing, distortion, bad anatomy, blurry, watermark, text, low quality, glitch"

if 'history' not in st.session_state: st.session_state.history = []
if 'last_result' not in st.session_state: st.session_state.last_result = None

# ==========================================
# ğŸ‘‡ 4. ä¾§è¾¹æ  (UI äº¤äº’ä¸­å¿ƒ) ğŸ‘‡
# ==========================================
with st.sidebar:
    if os.path.exists("elysia_cover.jpg"):
        st.image("elysia_cover.jpg", use_container_width=True)
        st.caption("âœ¨ â€œHi~ æ— è®ºè¿­ä»£å¤šå°‘æ¬¡ï¼Œæˆ‘éƒ½ä¸ä½ åŒåœ¨ï¼â€")

    st.markdown("### ğŸ¹ é­”æ³•é…ç½®")
    
    with st.expander("ğŸ¤– ç¬¬ä¸€æ­¥ï¼šè¿æ¥ AI å¤§è„‘", expanded=True):
        api_provider = st.selectbox("APIç±»å‹", ["è‡ªå®šä¹‰", "ç«å±±å¼•æ“ (è±†åŒ…)", "DeepSeek", "OpenAI"])
        
        # é»˜è®¤å€¼é˜²æ­¢æŠ¥é”™
        base, model = "", ""
        
        if api_provider == "ç«å±±å¼•æ“ (è±†åŒ…)":
            st.markdown("ğŸ‘‰ [**ç‚¹æˆ‘æ³¨å†Œè±†åŒ…**](https://www.volcengine.com/product/doubao)")
            base = "https://ark.cn-beijing.volces.com/api/v3"
        elif api_provider == "DeepSeek":
            st.markdown("ğŸ‘‰ [**ç‚¹æˆ‘æ³¨å†Œ DeepSeek**](https://platform.deepseek.com/)")
            base = "https://api.deepseek.com"; model = "deepseek-chat"
        elif api_provider == "OpenAI":
            st.markdown("ğŸ‘‰ [**OpenAI å®˜ç½‘**](https://platform.openai.com/)")
            base = "https://api.openai.com/v1"; model = "gpt-4o"

        api_key = st.text_input("API Key", type="password")
        
        if api_provider != "è‡ªå®šä¹‰":
            base_url = st.text_input("Base URL", value=base)
            model_name = st.text_input("Model", value=model, placeholder="è±†åŒ…è¯·å¡« Endpoint ID")
        else:
            base_url = st.text_input("Base URL")
            model_name = st.text_input("Model")

    st.markdown("---")
    st.markdown("#### ğŸ§ª Sora 2 ç‚¼é‡‘å°")
    
    col_ui1, col_ui2 = st.columns(2)
    with col_ui1:
        selected_style = st.selectbox("ğŸ”® é£æ ¼", list(PRESETS_STYLE.keys()))
    with col_ui2:
        selected_cam = st.selectbox("ğŸ“· è¿é•œ", list(PRESETS_CAMERA.keys()))
    
    style_content = PRESETS_STYLE[selected_style]
    cam_content = PRESETS_CAMERA[selected_cam]
    
    selected_phys = st.multiselect("ğŸŒŠ ç‰©ç†ä¸å…‰å½±", TAGS_PHYSICS, default=["Volumetric Lighting"])
    phys_content = ", ".join(selected_phys)
    
    selected_ratio_name = st.selectbox("ç”»å¹…æ¯”ä¾‹", list(RATIOS.keys()))
    target_size = RATIOS[selected_ratio_name]
    
    motion_strength = st.slider("âš¡ åŠ¨æ€å¹…åº¦", 1, 10, 5)
    neg_prompt = st.text_area("â›” è´Ÿé¢æç¤ºè¯", value=DEFAULT_NEG, height=70)

    st.markdown("---")
    c1, c2 = st.columns(2)
    with c1: border_width = st.slider("é—´è·", 0, 30, 15)
    with c2: output_quality = st.select_slider("ç”»è´¨", ["2K", "4K"], value="2K")
    scale_factor = 1.5 if output_quality == "4K" else 1.0

    st.markdown("---")
    with st.expander("â˜• æ‰“èµä½œè€… (å°è´¹)", expanded=False):
        if os.path.exists("pay.jpg"):
            st.image("pay.jpg", caption="æŠ•å–‚çµæ„Ÿ~", use_container_width=True)
        else:
            st.info("ï¼ˆç­‰å¾…æŠ•å–‚ä¸­...ï¼‰")

# ==========================================
# ğŸ‘‡ 5. ä¸»å·¥ä½œå° (Main Stage) ğŸ‘‡
# ==========================================

st.title("Miss Pink Elf's Studio v10.0")
st.markdown("**â€œè¦æŠŠè¿™ä¸€ç¬é—´ï¼Œå˜æˆæ°¸æ’çš„æ•…äº‹å—ï¼Ÿäº¤ç»™æˆ‘å§~â€**")

uploaded_files = st.file_uploader("ğŸ“‚ æ‹–å…¥å›¾ç‰‡å¼€å§‹åˆ›ä½œ (æ”¯æŒæ‰¹é‡)", type=['jpg', 'png', 'jpeg'], accept_multiple_files=True)

# ğŸ‘‰ è‹±é›„åŒºï¼šæ— æ–‡ä»¶æ—¶æ˜¾ç¤ºå¼•å¯¼
if not uploaded_files:
    st.markdown("<br>", unsafe_allow_html=True) 
    col_intro1, col_intro2, col_intro3 = st.columns(3)
    
    with col_intro1:
        st.markdown("""
        <div class="feature-card">
            <span class="emoji-icon">ğŸ§ </span>
            <h3>Sora 2 å†…æ ¸</h3>
            <p>åŸºäºå®˜æ–¹æ–‡æ¡£ä¼˜åŒ–çš„<br>ç‰©ç†å¼•æ“æç¤ºè¯é€»è¾‘</p>
        </div>
        """, unsafe_allow_html=True)
    with col_intro2:
        st.markdown("""
        <div class="feature-card">
            <span class="emoji-icon">ğŸ¬</span>
            <h3>AI å¯¼æ¼” v10</h3>
            <p>æ€ç»´é“¾ (CoT) åŠ æŒ<br>æ›´æ‡‚é•œå¤´è¯­è¨€ä¸å™äº‹</p>
        </div>
        """, unsafe_allow_html=True)
    with col_intro3:
        st.markdown("""
        <div class="feature-card">
            <span class="emoji-icon">ğŸŒ¸</span>
            <h3>å”¯ç¾ä½“éªŒ</h3>
            <p>æè‡´ä¸æ»‘çš„é¢„è§ˆæŠ€æœ¯<br>æ¨±èŠ±é›¨ä¸‹çš„åˆ›ä½œ</p>
        </div>
        """, unsafe_allow_html=True)

    st.markdown("---")
    st.info("ğŸ’¡ **V10.0 æ›´æ–°æ—¥å¿—:** ä¿®å¤äº†äº‘ç«¯å­—ä½“ Bugï¼Œç§»é™¤äº†æœ¬åœ°å¯åŠ¨ä»£ç ï¼Œä¼˜åŒ–äº†APIè¿æ¥é€»è¾‘ï¼Œæ–°å¢å†å²è®°å½•å’Œ TXT ä¸‹è½½ã€‚")

else:
    # æ’åºæ–‡ä»¶
    uploaded_files.sort(key=lambda x: x.name)
    
    with st.container():
        with st.form("storyboard_form"):
            st.write("#### ğŸ“ æ•…äº‹ç¼–ç»‡å°")
            shots_data = []
            cols = st.columns(3)
            shot_options = ["ECU (æç‰¹å†™)", "CU (ç‰¹å†™)", "MS (ä¸­æ™¯)", "LS (å…¨æ™¯)", "OTS (è¿‡è‚©)", "FPV (ç¬¬ä¸€äººç§°)"]
            
            for i, f in enumerate(uploaded_files):
                if i >= 9: break
                with cols[i % 3]:
                    thumb = load_preview_image(f)
                    st.image(thumb, use_container_width=True)
                    
                    c1, c2 = st.columns([1.5, 1])
                    with c1: s_type = st.selectbox("è§†è§’", shot_options, key=f"s_{i}", label_visibility="collapsed")
                    with c2: dur = st.number_input("ç§’", value=2.0, step=0.5, key=f"d_{i}", label_visibility="collapsed")
                    desc = st.text_input("æè¿°", placeholder="ä¾‹å¦‚ï¼šå¥³å­©å›å¤´...", key=f"t_{i}", label_visibility="collapsed")
                    shots_data.append({"file": f, "shot_code": s_type.split(" ")[0], "dur": dur, "desc": desc if desc else "Cinematic shot"})
            
            st.markdown("---")
            submit_btn = st.form_submit_button("âœ¨ æ–½å±•é­”æ³• (ç”Ÿæˆä¸“ä¸šåˆ†é•œ + å’’è¯­) âœ¨", type="primary", use_container_width=True)

    # ğŸ‘‰ ç”Ÿæˆé€»è¾‘
    if submit_btn:
        with st.status("ğŸ’ é­”æ³•å’å”±ä¸­...", expanded=True) as status:
            st.write("ğŸ–¼ï¸ æ­£åœ¨æ„å»ºé»‘åº•ç™½å­—ä¸“ä¸šåˆ†é•œ...")
            # å›¾ç‰‡å¤„ç†
            base_w, base_h = target_size
            final_w, final_h = int(base_w * scale_factor), int(base_h * scale_factor)
            count = len(shots_data)
            cols_count = 3
            rows_count = -(-count // cols_count)
            
            # ã€ä¸“ä¸šæ¨¡å¼ã€‘é»‘æ¡é«˜åº¦
            bar_height = int(final_h * 0.12)
            cell_h = final_h + bar_height
            
            total_w = (final_w * cols_count) + (border_width * (cols_count + 1))
            total_h = (cell_h * rows_count) + (border_width * (rows_count + 1))
            
            # ã€ä¸“ä¸šæ¨¡å¼ã€‘çº¯é»‘èƒŒæ™¯
            canvas = Image.new('RGB', (total_w, total_h), "#000000")
            draw = ImageDraw.Draw(canvas)
            font = get_font(int(bar_height * 0.5))
            
            for idx, item in enumerate(shots_data):
                src = Image.open(item["file"])
                src = ImageOps.fit(src, (final_w, final_h), method=Image.Resampling.LANCZOS)
                
                # ã€ä¸“ä¸šæ¨¡å¼ã€‘å•æ ¼ï¼šé»‘åº• + å·¦å¯¹é½ç™½å­—
                cell = Image.new('RGB', (final_w, cell_h), "#000000")
                cell.paste(src, (0, bar_height))
                
                info_text = f"KF{idx+1} [{item['shot_code']} | {item['dur']}s]"
                cdraw = ImageDraw.Draw(cell)
                
                text_padding_left = int(20 * scale_factor)
                text_bbox = cdraw.textbbox((0, 0), info_text, font=font)
                text_h = text_bbox[3] - text_bbox[1]
                text_y = (bar_height - text_h) / 2
                
                cdraw.text((text_padding_left, text_y), info_text, fill="#FFFFFF", font=font)
                
                r, c = idx // cols_count, idx % cols_count
                x = border_width + (c * (final_w + border_width))
                y = border_width + (r * (cell_h + border_width))
                canvas.paste(cell, (x, y))
            
            prompt_res = ""
            if api_key:
                st.write("ğŸ§  AI æ­£åœ¨æ€è€ƒå…‰å½±ä¸è¿é•œ (CoT)...")
                prompt_res = generate_sora_prompt_with_ai(
                    api_key, base_url, model_name, 
                    style_content, cam_content, phys_content, 
                    selected_ratio_name, motion_strength, neg_prompt, shots_data
                )
            else:
                st.warning("âš ï¸ æœªè¿æ¥ APIï¼Œè·³è¿‡æç¤ºè¯ç”Ÿæˆ")

            status.update(label="âœ¨ é­”æ³•å®Œæˆï¼", state="complete", expanded=False)
            
            # ä¿å­˜ç»“æœåˆ° Session
            st.session_state.last_result = {"image": canvas, "prompt": prompt_res}
            # (è¿­ä»£åŠŸèƒ½) åŠ å…¥å†å²åˆ—è¡¨
            st.session_state.history.append({"image": canvas, "prompt": prompt_res, "time": time.strftime("%H:%M")})
            gc.collect()

    # ğŸ‘‰ ç»“æœæ˜¾ç¤ºåŒº (ä» Session è¯»å–)
    if st.session_state.last_result:
        res = st.session_state.last_result
        st.balloons()
        
        tab1, tab2, tab3 = st.tabs(["ğŸ–¼ï¸ ä¸“ä¸šåˆ†é•œå›¾", "ğŸ“œ Sora 2 å’’è¯­", "ğŸ•°ï¸ å†å²è®°å½•"])
        
        with tab1:
            st.caption("âœ… å·²ä¸¥æ ¼éµå¾ªå‚è€ƒå›¾æ ¼å¼ï¼šé»‘åº•ã€ç™½å­—ã€å·¦å¯¹é½ã€‚Sora 2 å¯å®Œç¾è¯†åˆ«ã€‚")
            st.image(res["image"], use_container_width=True)
            buf = io.BytesIO()
            res["image"].save(buf, format="JPEG", quality=95, subsampling=0)
            st.download_button("ğŸ“¥ ä¸‹è½½ä¸“ä¸šåˆ†é•œå›¾", buf.getvalue(), "sora_storyboard_pro.jpg", "image/jpeg")
            
        with tab2:
            if res["prompt"]:
                st.code(res["prompt"], language="text")
                st.download_button("ğŸ“„ ä¸‹è½½æç¤ºè¯ (.txt)", res["prompt"], "prompt.txt", "text/plain")
            else:
                st.info("æœ¬æ¬¡ä»…ç”Ÿæˆäº†å›¾ç‰‡ï¼Œå¡«å†™ API Key å¯ç”Ÿæˆæç¤ºè¯ã€‚")
        
        with tab3:
            st.caption("æœ¬æ¬¡ä¼šè¯çš„å†å²ç”Ÿæˆè®°å½• (åˆ·æ–°åæ¶ˆå¤±)")
            for i, h in enumerate(reversed(st.session_state.history[:-1])): 
                with st.expander(f"ğŸ•’ è®°å½• {h.get('time', i)}"):
                    st.image(h['image'], use_container_width=True)
                    if h['prompt']: st.code(h['prompt'])
